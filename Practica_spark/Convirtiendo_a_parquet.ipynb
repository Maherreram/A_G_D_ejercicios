{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librearìa que busca el servicio de spak\n",
    "import findspark\n",
    "\n",
    "#Librerìas para gestionar el servicio\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Iniciación de sesion\n",
    "findspark.init()\n",
    "\n",
    "#Creamos la conf de spak y seteamos un nombre para la aplicación\n",
    "sparkConf = SparkConf().setAppName(\"Convertir Parquet\")\n",
    "sc = SparkContext(conf=sparkConf)  #Creamos el contexto: Es como un string de conexion a unos contestos \"x\" y unas aplicaciones que estamos usando\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hdfs dfs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copyFromLocal: `/tmp/credit.csv': File exists\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -copyFromLocal credit.csv /tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos el dataframe con el archivo .csv\n",
    "creditos = spark.read.load('/tmp/credit.csv',\n",
    "                           format=\"csv\",\n",
    "                           sep=',',\n",
    "                           inferSchema='true',\n",
    "                           header='true')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de no correr el siguiete comando, debe tenerse en cuenta que el parquet ya se encuentre instalado. En caso de no estar instalado debe ejecutarse el comando \n",
    "\n",
    "!pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La sigueinte instruccion particiona el archivo en un elemento, escribe en modo de sobreescritura (en caso que ya exista) \n",
    "#y lo crea con un nuevo formato, en este caso formato parquet\n",
    "creditos.repartition(1).write.mode('overwrite').parquet('/tmp/credits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "-rw-r--r--   1 root supergroup     133638 2021-05-17 19:29 /tmp/credit.csv\n",
      "drwxr-xr-x   - root supergroup          0 2021-05-17 20:46 /tmp/credits\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer o cargar los datos en formato parquet\n",
    "dfparquet = spark.read.parquet('/tmp/credits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+------+\n",
      "|credit_history|   purpose|amount|\n",
      "+--------------+----------+------+\n",
      "|      critical|  radio/tv|  1169|\n",
      "|        repaid|  radio/tv|  5951|\n",
      "|      critical| education|  2096|\n",
      "|        repaid| furniture|  7882|\n",
      "|       delayed| car (new)|  4870|\n",
      "|        repaid| education|  9055|\n",
      "|        repaid| furniture|  2835|\n",
      "|        repaid|car (used)|  6948|\n",
      "|        repaid|  radio/tv|  3059|\n",
      "|      critical| car (new)|  5234|\n",
      "+--------------+----------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Imprimir las 10 primeras filas usando parquet\n",
    "dfparquet.select(['credit_history', 'purpose','amount']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
